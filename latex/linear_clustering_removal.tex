\documentclass{report}

\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{bm}

\begin{document}

\chapter{Blinding with Linear Clustering Removal}
\author{Samuel Wehrli}
\date{\today}
%\maketitle

Face recognition algorithms work with embedding spaces. They map images of persons into the embedding space such that images of the same person are close to each other in the embedding space. This work investigates discriminatory dimensions in face recognition algorithms. For a given discriminatory dimension, the data can be grouped into clusters. A blinding procedure is proposed to remove the information related to the separation of these clusters. The procedure is a linear operation in the embedding space and uses the following steps:

\begin{enumerate}
	\item Compute centers of clusters defined by the discriminatory dimension.
	\item Use a one-vs-rest (OvR) Ansatz to calculate the directions of discrimination of each cluster relative to the other clusters.
	\item Apply singalur value decomposition (SVD) on the directions of discrimination to find an orthonormal basis spanning the ``discriminatory subspace''.
	\item Remove projections onto the ``discriminatory subspace'' from the embedding vectors. This results in embedding vectors which are orthogonal to the directions of discrimination.
\end{enumerate} 

\noindent After outlining the method,  cluster visualization, awareness and face recognition rates are investigated before and after the blinding procedure.

\section{The math behind}

In the following we look at the discriminatory dimension of race. We work with the commonly used racial faces in-the-wild (RFW) data set which groups faces into $K=4$ ethnic clusters Caucasian, African, Asian and Indian. I consider a VGG2 model where the embedding space has $N_e=128$ dimensions. The procedure outlined above operates on the empedding vectors $\bm{x}_i$ where $i$ denotes the sample. Associated to each sample is a cluster label $k\in\{1,\ldots, K\}$. As stated, the goal is to remove the directions in the embedding space which separate the ethnic clusters. As a first step, we define the centers of each cluster by the average

\begin{equation}
\label{eq:xbar}
	\bar{\bm{x}}_k = \frac{1}{n_k}\sum_{i\in C_k}\bm{x}_i ,
\end{equation} 

\noindent where $C_k$ is the set of embedding vectors associated with cluster k and $n_k$ is the corresponding size. Following a one-vs-rest (OvR) approach, the normalized direction of discrimination of each cluster $k$ to the other clusters is given by the vectors

\begin{equation}
\label{eq:uk}
	\bm{u}_k = \frac{\bm{v}_k}{\Vert \bm{v}_k \Vert} \quad \textrm{with} \quad \bm{v}_k = \bar{\bm{x}}_k -  \frac{1}{K-1}\sum_{k' \ne k} \bar{\bm{x}}_{k'},
\end{equation} 

\begin{figure}
  \includegraphics[width=\linewidth]{projection.eps}
  \caption{Kernel density estimation (KDE) plot of the projections  ($\bm{x}_i\cdot \bm{u}_k$). The normalized directions $\bm{u}_k$ represent the discriminatory directions which separate each cluster from the others.}
  \label{fig:projection}
\end{figure}

\noindent where $K$ is the number of clusters. Fig.~\ref{fig:projection} shows the projections onto the vectors $\bm{u}_k$. As it may be expected from the construction, each direction nicely separates the corresponding cluster from the others. These means, that different ethnic groups are literally located in different corners of the empedding space. By construction, the vectors $\bm{u}_k$ are not linearly independent, but span a subspace of rank $K-1$. This can by verified by applying a singular value decomposition (SVD) on the matrix $U=[\bm{u}_1\ldots \bm{u}_K]$. SVD also provides a orthonormal basis $B=[\bm{e}_1\ldots \bm{e}_{K-1}]$ of the corresponding subspace. The final step is to remove the projections onto this subspace by

\begin{equation}
\label{eq:xb}
	\bm{x}_i^{b} = \bm{x}_i - \sum_{j=1}^{K-1} (\bm{x}_i\cdot \bm{e}_j)\,\bm{e}_j,
\end{equation} 

\noindent where $(\bm{x}_i\cdot \bm{e}_j)$ is the dot (or scalar) product.  Eq.~(\ref{eq:xb}) yields new embedding vectors $\bm{x}_i^{b}$ with the same shape as the original ones. The upper index $b$ stands for \emph{blinded} inspired by the fact that some information with regard to the discriminatory dimension has been removed. Note that the new embeddings depend linearly on the original ones. 
   

\section{Awareness}

Awareness is the ability of the model to discriminate between different clusters of the discriminatory dimensions, being the ethnic label in present case. This ability obviously depends on the trained model at hand. Here I benchmark the performance to predict the ethnic labels by the \emph{aware} embeddings $\bm{x}_i$ and the \emph{blinded} ones $\bm{x}_i^{b}$.  A train/test split of two thirds/one third was used. The accuracy of different classifiers is shown in Tab.~\ref{tab:awareness}. Not surprisingly, linear classifiers are unable to predict the race for the blinded embeddings. Nearest neighbor approaches still work reasonably. More advanced non-linear classifiers such as neural networks perform well. The clustering displayed by the corresponding t-SNE plots in Fig.~\ref{fig:tSNE} is in line with these findings. In the blinded case, clusters can't be separated be a single straight line. However, the data still displays groups defined by ethnical labels. Interestingly, there are clear differences between the groups. Africans are grouped in the center, Caucasian encircle the cloud and Indians/Asian are scattered inbetween. 

\begin{table}
\begin{center}
\begin{tabular}{ c|c|c  }
Model & aware  & blinded  \\
\hline
Logistic regression & 96\% & 21\% \\ 
Linear SVM & 96\% & 26\% \\  
Nearest neighbor & 92\% &  57\%  \\   
5 Nearest neighbor & 94\% &  62\%  \\   
NN with 1 hidden layer (100 nodes), relu  & 96\% &  70\%  \\   
NN with 2 hidden layer (100 nodes each), relu  & 96\% &  85\%    
\end{tabular}
\end{center}
\caption{Subset accuracy of various classifiers predicting the ethnic labels based on \emph{aware}  and \emph{blinded} emdeddings. A train/test split of two thirds/one third was used.}
\label{tab:awareness}
\end{table}

\begin{figure}
  \includegraphics[width=0.5\textwidth]{t-SNE_aware.png}
  \includegraphics[width=0.5\textwidth]{t-SNE_blinded.png}
  \caption{tSNE plots of the two embeddings}
  \label{fig:tSNE}
\end{figure}


\section{Cluster scores}

Cluster scores give a measure of clustering. They are calculated for both embeddings in Tab.~\ref{tab:cluster}. The Silhoutte cluster score gives a measure between 0 and 1 indicating how well the data is clustered. The Silhoutte cluster score of the aware embeddings is only 0.063 -  basically indicating the absence of clustering although Fig.~\ref{fig:projection} and Fig.~\ref{fig:tSNE} show nice clustering for the aware embeddings. This counter-intuitive finding is due to the high dimensionality. Both figures show projections into lower dimensions and therefore reflect only a marginal part of the information. This is confirmed by the fact that the total variance of the blinded embeddings is still 84\% of the original variance.   

\begin{table}
\begin{center}
\begin{tabular}{ c|c|c }
Cluster score & aware  & blinded  \\
\hline
Silhouette score & 0.063 & -0.014 \\ 
Calinski-Harabasz score & 1814 & 0 \\  
Davies-Bouldin score & 3.8 & 2.8x$10^6$  
\end{tabular}
\end{center}
\caption{Cluster scores for  \emph{aware}  and  \emph{blinded} emdeddings.}
\label{tab:cluster}
\end{table}

\section{Face recognition rates and bias}

\subsection{Positive / negative pair metric}

Face recognition rates and bias are evaluated with the RFW data set. The RFW dataset provides image (i.e. embedding) pairs corresponding to the same or to different persons. The resulting task is a binary classification of the pairs into ``same'' and ``different''. Note that pairs are withing the ethnic group (which turns out to be critical, as shown in the next subsection). The recognition rate is the accuracy of the corresponding classification. The feature used for the classification is the pair distance in the embedding space. Here we use the cosine distance:

\begin{equation}
\label{eq:cos}
	d_{ij} = 1 - \frac{\bm{x}_i\cdot \bm{x}_j}{\Vert \bm{x}_i \Vert\,\Vert \bm{x}_j \Vert }
\end{equation} 

\noindent The face recognition rates calculated in this way are shown in  Tab.~\ref{tab:frrate}. The table includes further Senet models with $N_e=256, 2048$. Surprisingly, the performance increases for the blinded embeddings by about 2\% for all clusters. Bias is slightly removed.  Fig.~\ref{fig:frrate} gives further insights by showing the distribution of the cosine distances for ``same'' and ``different'' pairs. The Caucasians are special in that their distributions are not significantly altered. Note that the blinding procedure leads to a better alignment of the thresholds. 


\begin{table}
\begin{center}
\begin{tabular}{ c|c|c || c|c || c|c }
$N_e$ & 128 & 128 & 256 & 256 & 2048 & 2048 \\
        & aware  & blinded  & aware  & blinded  & aware  & blinded  \\
\hline
Total & 86\% & 88\%           &  86\% & 88\%    &  83\% & 84\%  \\ 
\hline
Caucasian & 91\% & 92\%    &  91\% & 92\%    &  89\% & 89\% \\  
Indian & 86\% & 88\%          &  86\% & 88\%    &  85\% & 85\%\\ 
Asian & 84\% & 86\%           &  84\% & 87\%    &  82\% & 82\%\\ 
African & 84\% &    86\%      &  84\% & 85\%    &  76\% & 79\% 
\end{tabular}
\end{center}
\caption{Face recognition rates of the RFW dataset for \emph{aware}  and  \emph{blinded} emdeddings and for different Senet models indicated by the embedding size $N_e$. The threshold was optimized for each case (corresponding to a column) with respect to the total dataset.}
\label{tab:frrate}
\end{table}

\begin{figure}
  \includegraphics[width=\textwidth]{bias.eps}
  \caption{Kernel density estimation (KDE) plot of pairwise cosine distances for same persons (green) and different persons (red) and for  \emph{aware} (darker color) and  \emph{blinded} (lighter color) emdeddings.}
  \label{fig:frrate}
\end{figure}

\subsection{Nearest neighbor metric}

Given a set of images, an alternative way to assess bias is to look at the nearest neighbors and whether the corresponding images belong to the same person or not. This can again be done for the \emph{aware}  and  \emph{blinded} emdeddings. Again, the cosine distance is used as defined in Eq.~(\ref{eq:cos}). The result is shown in Tab.~\ref{tab:nnrate} together with error rates which show whether nearest neighbors belong to the same ethnic group or to a different one (if it is not the same person). With this metric, the blinding reduces performance. Altough the confusion with persons of the same ethnic group is reduced upon blinding, confusion with persons from different ethnic groups overcompensates the reduction leading to an overall performance decrease.   

\begin{table}
\begin{center}
\begin{tabular}{ c|c|c | c||c | c|c }
        & aware  & aware  & aware  & blinded  & blinded  & blinded  \\
     & acc & err. rate & err. rate & acc & err. rate & err. rate \\
     &  & eq. group  & diff. group &  & eq. group  & diff. group  \\
\hline
Caucasian & 90\% &  8\%    &  2\% & 86\%    &  6\% & 8\% \\  
Indian       & 85\% & 13\%   &  2\% & 83\%    &  9\% & 8\%\\ 
Asian        & 83\% & 16\%   &  1\% & 80\%    &  13\% & 7\%\\ 
African      & 80\% & 19\%   &  1\% & 78\%    &  16\% & 6\% 
\end{tabular}
\end{center}
\caption{Face recognition rates by nearest neighbor metric for \emph{aware}  and  \emph{blinded} emdeddings and the $N_e=128$ model. Accuracies are given for each ethnic group. Errors correspond to the remaining accuracy gap. If the nearest neighbor does not belong to the same person, the equal group error rate indicates whether the nearest neighbor belongs to the same group. Similarly, the different group error rate corresponds to nearest neighbors of a different ethnic group.}
\label{tab:nnrate}
\end{table}


\section{Discussion}

The proposed procedure removes linear separability with the effect that linear classifiers can't distinguish between ethnic clusters after blinding. Clustering as measured by cluster validation scores completely vanishes with this blinding procedures. This leads to the first insight

\begin{quote}
    Cluster validation scores are not a measure of bias. They indicate whether linear classifiers can predict clusters of the discriminatory dimension - a property which is related to awareness.
 \end{quote}

\noindent The fact that the ethnic clusters are well separated in the first place shows that the considered model clearly distinguishes the ethnic groups. The blinding removes this separation. 

Two measures were considered to assess face recognition rates and bias:

\begin{enumerate}
	\item Classification of positive and negative pairs 
	\item Nearest neighbors
\end{enumerate}

\noindent To my knowledge, the first method is widely used. Surprisingly, the performance increases and and the bias is slightly reduced. With the second measure, performance is significantly reduced and bias again slightly. The reason for the different outcomes is the fact that the pair method only uses pairs within the same ethnic cluster and blinding actually increases the performance within a given cluster. This leads to the second insight

\begin{quote}
    Measuring face recognition rates and bias with a pair approach can be misleading when images of any given pairs are within the same cluster. 
 \end{quote}

\noindent Yet another (commonly used) way of how not to measure bias was identified...


\end{document}