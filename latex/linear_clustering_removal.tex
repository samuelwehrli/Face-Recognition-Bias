\documentclass{report}

\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{bm}

\begin{document}

\chapter{Blinding with Linear Clustering Removal}
\author{Samuel Wehrli}
\date{\today}
%\maketitle

Face recognition algorithms work with embedding spaces. They map images of persons into the embedding space such that images of the same person are close to each other in the embedding space. This work investigates discriminatory dimensions in face recognition algorithms. For a given discriminatory dimension, the data can be grouped into clusters. A blinding procedure is proposed to remove the information related to the separation of these clusters. The procedure is a linear operation in the embedding space and uses the following steps:

\begin{enumerate}
	\item Compute centers of clusters defined by the discriminatory dimension.
	\item Use a one-vs-rest (OvR) Ansatz to calculate the directions of discrimination of each cluster relative to the other clusters.
	\item Apply singalur value decomposition (SVD) on the directions of discrimination to find an orthonormal basis spanning the ``discriminatory subspace''.
	\item Remove projections onto the ``discriminatory subspace'' from the embedding vectors. This results in embedding vectors which are orthogonal to the directions of discrimination.
\end{enumerate} 

\noindent After outlining the method,  cluster visualization, awareness and face recognition rates are investigated before and after the blinding procedure.

\section{The math behind}

In the following we look at the discriminatory dimension of race. We work with the commonly used racial faces in-the-wild (RFW) data set which groups faces into $K=4$ ethnic clusters Caucasian, African, Asian and Indian. I consider a VGG2 model where the embedding space has $N_e=128$ dimensions. The procedure outlined above operates on the empedding vectors $\bm{x}_i$ where $i$ denotes the sample. Associated to each sample is a cluster label $k\in\{1,\ldots, K\}$. As stated, the goal is to remove the directions in the embedding space which separate the ethnic clusters. As a first step, we define the centers of each cluster by the average

\begin{equation}
\label{eq:xbar}
	\bar{\bm{x}}_k = \frac{1}{n_k}\sum_{i\in C_k}\bm{x}_i ,
\end{equation} 

\noindent where $C_k$ is the set of embedding vectors associated with cluster k and $n_k$ is the corresponding size. Following a one-vs-rest (OvR) approach, the normalized direction of discrimination of each cluster $k$ to the other clusters is given by the vectors

\begin{equation}
\label{eq:uk}
	\bm{u}_k = \frac{\bm{v}_k}{\Vert \bm{v}_k \Vert} \quad \textrm{with} \quad \bm{v}_k = \bar{\bm{x}}_k -  \frac{1}{K-1}\sum_{k' \ne k} \bar{\bm{x}}_{k'},
\end{equation} 

\begin{figure}
  \includegraphics[width=\linewidth]{projection.eps}
  \caption{Kernel density estimation (KDE) plot of the projections  ($\bm{x}_i\cdot \bm{u}_k$). The normalized directions $\bm{u}_k$ represent the discriminatory directions which separate each cluster from the others.}
  \label{fig:projection}
\end{figure}

\noindent where $K$ is the number of clusters. Fig.~\ref{fig:projection} shows the projections onto the vectors $\bm{u}_k$. As it may be expected from the construction, each direction nicely separates the corresponding cluster from the others. These means, that different ethnic groups are literally located in different corners of the empedding space. By construction, the vectors $\bm{u}_k$ are not linearly independent, but span a subspace of rank $K-1$. This can by verified by applying a singular value decomposition (SVD) on the matrix $U=[\bm{u}_1\ldots \bm{u}_K]$. SVD also provides a orthonormal basis $B=[\bm{e}_1\ldots \bm{e}_{K-1}]$ of the corresponding subspace. The final step is to remove the projections onto this subspace by

\begin{equation}
\label{eq:xb}
	\bm{x}_i^{b} = \bm{x}_i - \sum_{j=1}^{K-1} (\bm{x}_i\cdot \bm{e}_j)\,\bm{e}_j,
\end{equation} 

\noindent where $(\bm{x}_i\cdot \bm{e}_j)$ is the dot (or scalar) product.  Eq.~(\ref{eq:xb}) yields new embedding vectors $\bm{x}_i^{b}$ with the same shape as the original ones. The upper index $b$ stands for \emph{blinded} inspired by the fact that some information with regard to the discriminatory dimension has been removed. Note that the new embeddings depend linearly on the original ones. 
   

\section{Awareness}

Awareness is the ability of the model to discriminate between different clusters of the discriminatory dimensions, being the ethnic label in present case. This ability obviously depends on the trained model at hand. Here I benchmark the performance to predict the ethnic labels by the \emph{aware} embeddings $\bm{x}_i$ and the \emph{blinded} ones $\bm{x}_i^{b}$.  A train/test split of two thirds/one third was used. The accuracy of different classifiers is shown in Tab.~\ref{tab:awareness}. Not surprisingly, linear classifiers are unable to predict the race for the blinded embeddings. Nearest neighbor approaches still work reasonably. More advanced non-linear classifiers such as neural networks perform well. The clustering displayed by the corresponding t-SNE plots in Fig.~\ref{fig:tSNE} is in line with these findings. In the blinded case, clusters can't be separated be a single straight line. However, the data still displays groups defined by ethnical labels. Interestingly, there are clear differences between the groups. Africans are grouped in the center, Caucasian encircle the cloud and Indians/Asian are scattered inbetween. 

\begin{table}
\begin{center}
\begin{tabular}{ c|c|c  }
Model & aware  & blinded  \\
\hline
Logistic regression & 96\% & 21\% \\ 
Linear SVM & 96\% & 26\% \\  
Nearest neighbor & 92\% &  57\%  \\   
5 Nearest neighbor & 94\% &  62\%  \\   
NN with 1 hidden layer (100 nodes), relu  & 96\% &  70\%  \\   
NN with 2 hidden layer (100 nodes each), relu  & 96\% &  85\%    
\end{tabular}
\end{center}
\caption{Subset accuracy of various classifiers predicting the ethnic labels based on \emph{aware}  and \emph{blinded} emdeddings. A train/test split of two thirds/one third was used.}
\label{tab:awareness}
\end{table}

\begin{figure}
  \includegraphics[width=0.5\textwidth]{t-SNE_aware.png}
  \includegraphics[width=0.5\textwidth]{t-SNE_blinded.png}
  \caption{tSNE plots of the two embeddings}
  \label{fig:tSNE}
\end{figure}


\section{Cluster scores}

Cluster scores give a measure of clustering. They are calculated for both embeddings in Tab.~\ref{tab:cluster}. The Silhoutte cluster score gives a measure between 0 and 1 indicating how well the data is clustered. The Silhoutte cluster score of the aware embeddings is only 0.063 -  basically indicating the absence of clustering although Fig.~\ref{fig:projection} and Fig.~\ref{fig:tSNE} show nice clustering for the aware embeddings. This counter-intuitive finding is due to the high dimensionality. Both figures show projections into lower dimensions and therefore reflect only a marginal part of the information. This is confirmed by the fact that the total variance of the blinded embeddings is still 84\% of the original variance.   

\begin{table}
\begin{center}
\begin{tabular}{ c|c|c }
Cluster score & aware  & blinded  \\
\hline
Silhouette score & 0.063 & -0.014 \\ 
Calinski-Harabasz score & 1814 & 0 \\  
Davies-Bouldin score & 3.8 & 2.8x$10^6$  
\end{tabular}
\end{center}
\caption{Cluster scores for  \emph{aware}  and  \emph{blinded} emdeddings.}
\label{tab:cluster}
\end{table}

\section{Face recognition rates and bias}

Face recognition rates and bias are evaluated with the RFW data set. The RFW dataset provides image (i.e. embedding) pairs corresponding to the same or to different persons. The resulting task is a binary classification of the pairs into ``same'' and ``different''. The recognition rate is the accuracy of the corresponding classification. The feature used for the classification is the pair distance in the embedding space. Here we use the cosine distance:

\begin{equation}
\label{eq:cos}
	d_{ij} = 1 - \frac{\bm{x}_i\cdot \bm{x}_j}{\Vert \bm{x}_i \Vert\,\Vert \bm{x}_j \Vert }
\end{equation} 

\noindent The face recognition rates calculated in this way are shown in  Tab.~\ref{tab:frrate}. The table includes further Senet models with $N_e=256, 2048$. Surprisingly, the performance increases for the blinded embeddings by about 2\% for all clusters. Bias is slightly removed.  Fig.~\ref{fig:frrate} gives further insights by showing the distribution of the cosine distances for ``same'' and ``different'' pairs. The Caucasians are special in that their distributions are not significantly altered. Note that the blinding procedure leads to a better alignment of the thresholds. 


\begin{table}
\begin{center}
\begin{tabular}{ c|c|c || c|c || c|c }
$N_e$ & 128 & 128 & 256 & 256 & 2048 & 2048 \\
        & aware  & blinded  & aware  & blinded  & aware  & blinded  \\
\hline
Total & 86\% & 88\%           &  86\% & 88\%    &  83\% & 84\%  \\ 
\hline
Caucasian & 91\% & 92\%    &  91\% & 92\%    &  89\% & 89\% \\  
Indian & 86\% & 88\%          &  86\% & 88\%    &  85\% & 85\%\\ 
Asian & 84\% & 86\%           &  84\% & 87\%    &  82\% & 82\%\\ 
African & 84\% &    86\%      &  84\% & 85\%    &  76\% & 79\% 
\end{tabular}
\end{center}
\caption{Face recognition rates of the RFW dataset for \emph{aware}  and  \emph{blinded} emdeddings and for different Senet models indicated by the embedding size $N_e$. The threshold was optimized for each case (corresponding to a column) with respect to the total dataset.}
\label{tab:frrate}
\end{table}

\begin{figure}
  \includegraphics[width=\textwidth]{bias.eps}
  \caption{Kernel density estimation (KDE) plot of pairwise cosine distances for same persons (green) and different persons (red) and for  \emph{aware} (darker color) and  \emph{blinded} (lighter color) emdeddings.}
  \label{fig:frrate}
\end{figure}

\section{Discussion}

Most of the findings with regard to the blinding procedures are not surprising. The proposed procedure removes linear separability with the effect that linear classifiers can't distinguish between ethnic clusters after blinding in line with the cluster scores. The fact that the ethnic clusters are well separated in the first place shows that the considered model clearly distinguishes the ethnic groups. The blinding removes this separation. The surprise comes at the end. The removal of this information actually improves overall performance and slightly reduces bias. The performance improvement through this simple linear approach is very surprising. A reason might be that there are a substantial differences between the data used for training of the model and the RFW data used for present benchmark. At this stage it is not clear, whether this performance improvement is accidental or generalizes to other models and other discriminatory dimensions.


\end{document}